{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the LISAandNEA process end-to-end for a bunch of datasets and classifiers\n",
    "\n",
    "To be parameterised with Papermill, a notebook needs a cell tagged \"parameters\"\n",
    "\n",
    "1. Open the notebook in VSC's built-in text editor \n",
    "2. Find the cell \n",
    "3. Replace ```\"metadata\": {},``` with ```\"metadata\": { \"tags\": [ \"parameters\" ] },```\n",
    "4. Save the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import papermill as pm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress 'Black is not installed' warning from papermill\n",
    "# Credit: https://github.com/ploomber/ploomber/pull/831/files\n",
    "\n",
    "class IgnoreBlackWarning(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return 'Black is not installed' not in record.msg\n",
    "\n",
    "logging.getLogger(\"papermill.translators\").addFilter(IgnoreBlackWarning())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifiers = ['cnn', 'fcn', 'resnet11']\n",
    "epochs = 1000\n",
    "all_df = [1, 2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for df_iter in all_df:\n",
    "    \n",
    "    # Processing loop for dataset N\n",
    "    dataset_name = f'df{df_iter}'\n",
    "    timestamp = datetime.today().strftime('%Y%m%d_%H%M%S')\n",
    "    run_id = f'{dataset_name}_{timestamp}'\n",
    "\n",
    "    # Run lisadatasets3.ipynb to define the dataset's instances\n",
    "    print(f'Running lisadatasets for {dataset_name} at {datetime.today()}')\n",
    "    pm.execute_notebook(\n",
    "        'lisadatasets3.ipynb',\n",
    "        f'lisadatasets3_{dataset_name}.ipynb',\n",
    "        parameters = dict(\n",
    "            df_iter = df_iter,\n",
    "            save_file = True\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Run lisaglitches6.ipynb to create simulated telemetry\n",
    "    # in 3 chunks to avoid kernel panic at ~2000+ instances\n",
    "    for chunk in range(3):\n",
    "\n",
    "        print(f'Running lisaglitches5 for {dataset_name} chunk {chunk} at {datetime.today()}')\n",
    "        pm.execute_notebook(\n",
    "            'lisaglitches6.ipynb',\n",
    "            f'lisaglitches6_{dataset_name}_{chunk}.ipynb',\n",
    "            parameters = dict(\n",
    "                dataset_name = dataset_name,\n",
    "                timestamp = timestamp,\n",
    "                first_instance = 1000*chunk,\n",
    "                instances_to_do = 1000\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Run lisa_to_tsc2.ipynb to create dataset\n",
    "    print(f'Running lisa_to_tsc for {dataset_name} at {datetime.today()}')\n",
    "    pm.execute_notebook(\n",
    "        'lisa_to_tsc2.ipynb',\n",
    "        f'lisa_to_tsc2_{dataset_name}.ipynb',\n",
    "        parameters = dict(\n",
    "            run_id = run_id\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dataset_name = f'{dataset_name}_{timestamp}'\n",
    "\n",
    "    # Run tsc_generic2.ipynb to train and test the classifiers\n",
    "    for classifier_name in all_classifiers:\n",
    "        \n",
    "        print(f'Running tsc_generic for {dataset_name} with {classifier_name} at {datetime.today()}')\n",
    "        pm.execute_notebook(\n",
    "            'tsc_generic2.ipynb',\n",
    "            f'tsc_generic2_{dataset_name}_{classifier_name}.ipynb',\n",
    "            parameters = dict(\n",
    "                dataset_name = dataset_name,\n",
    "                classifier_name = classifier_name,\n",
    "                epochs = epochs\n",
    "            )\n",
    "        )        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36466534b9494da9b96c3dc3c9d50c6000192fd0b07a68f54654207be0196115"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
